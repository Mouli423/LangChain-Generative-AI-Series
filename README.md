This repository is part of my LinkedIn learning series on Generative AI with LangChain.
It provides a structured, end-to-end roadmap — starting from theoretical foundations to hands-on implementation of LangChain pipelines.

Each folder in this repo corresponds to one topic or LinkedIn post, including:

 Concept explanation (in Markdown)

Architecture or workflow diagram

Mini code examples or Jupyter notebooks

Links to reference articles and future projects

The goal is to help learners, developers, and AI enthusiasts understand how LangChain simplifies LLM app development — by combining prompts, chains, memory, tools, and retrievers in a modular pipeline.

* Topics covered (growing weekly):

1. Generative AI with LangChain (Introduction)
2. LangChain Key Components
3. LangChain Architecture & Pipeline
4. Environment Setup
5. Document Loaders
6. Text Splitters
7. Embeddings
8. Prompt Templates
9. Chat Models & Messages
10. Chains
11. Vector Stores
12. Retrievers
13. Memory & Chat History Management
14. LCEL & Runnables
15. Prompt Engineering & Techniques

End Goal:
Build complete Generative AI apps — from document Q&A to AI-powered assistants — while understanding the why behind each LangChain component.

Tech Stack:
Python, LangChain, OpenAI, FAISS/Chroma, Streamlit (for deployment demos)

Follow the series on LinkedIn:
I’ll post weekly explanations + repo updates with code snippets and diagrams.
