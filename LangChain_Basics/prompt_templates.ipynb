{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "272b0575",
   "metadata": {},
   "source": [
    "## LangChain Generative AI Series — Prompt Templates\n",
    "\n",
    "\n",
    "###  Introduction\n",
    "- Prompt Templates are a core concept in LangChain that let you dynamically construct prompts for LLMs.\n",
    "- They make your GenAI pipelines modular, reusable, and consistent.\n",
    "\n",
    "\n",
    "### Why Prompt Templates Are Needed\n",
    "- When building with LLMs, you often need to pass dynamic inputs (user queries, context, etc.) and maintain consistent structure.\n",
    "- Prompt templates help avoid duplication and make experimentation easier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e7efff",
   "metadata": {},
   "source": [
    "### PromptTemplate\n",
    "- These prompt templates are used to format a single string, and generally are used for simpler inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2d581e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'write an eassay on Environmental issues'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template=PromptTemplate.from_template(\"write an eassay on Environmental issues\")\n",
    "\n",
    "prompt_template.format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21868dd7",
   "metadata": {},
   "source": [
    "### PromptTemplate With Variables\n",
    "- When we have a template string, which we want to dynamically be able to replace certain parts of that string only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdee8221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'write an essay on Geneartive AI.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template=PromptTemplate.from_template(\"write an essay on {topic}.\")\n",
    "prompt_template.format(topic=\"Geneartive AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e44e00bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='write an essay on Generative AI.')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.invoke({\"topic\":\"Generative AI\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b2aab7",
   "metadata": {},
   "source": [
    "### Using PromptTemplate Constructor\n",
    "- We can also create a PromptTemplate via the constructor, instead of via the from_template method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72070eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Write an essay on Agentic AI in 500 words.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template=PromptTemplate(\n",
    "    template=\"Write an essay on {topic} in {length} words.\",\n",
    "    input_variables=['topic','length']\n",
    ")\n",
    "\n",
    "prompt_template.invoke({'topic':'Agentic AI','length':'500'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e38fe0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write an essay on Agentic AI in 500 words.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.format(topic='Agentic AI',length='500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4827b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='you are a helpful eassy writer.\\nwrite precise and consise essays based on the query.\\n\\nquestion: write an essay on Machine Learning in 600 words.\\n\\nanswer:\\n')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template=\"\"\"you are a helpful eassy writer.\n",
    "write precise and consise essays based on the query.\n",
    "\n",
    "question: write an essay on {topic} in {length} words.\n",
    "\n",
    "answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt_template=PromptTemplate.from_template(template=template)\n",
    "\n",
    "prompt_template.invoke({'topic':'Machine Learning','length':'600'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120d481c",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate\n",
    "- ChatPromptTemplate is used to build structured prompts for chat-based LLMs such as GPT, Claude, or Gemini.\n",
    "Instead of plain text, it organizes messages by roles — typically system, human, and ai.\n",
    "\n",
    "- It helps maintain tone, context, and control over how the model responds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d98480c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful Essay writer. Your name is Moon.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you doing?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing well, thanks!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Write an essay on RAG?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful Essay writer. Your name is {name}.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "template.invoke(\n",
    "    {\n",
    "        \"name\": \"Moon\",\n",
    "        \"user_input\": \"Write an essay on RAG?\",\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73f30a9",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate With MessagePlaceholder\n",
    "\n",
    "- In a ChatPromptTemplate, we can format multiple messages, such as system and user messages. However, there are cases where we need to insert a dynamic - list of messages — for example, a conversation history or context generated during runtime.\n",
    "\n",
    "- To handle this, LangChain provides the MessagesPlaceholder component. It allows you to designate a specific placeholder within your prompt where a list of messages can be dynamically inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbca6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful Essay Writer.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}), AIMessage(content='How can I assist you today?', additional_kwargs={}, response_metadata={}), HumanMessage(content='Write an essay on AI Agents? ', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful Essay Writer.\"),\n",
    "        MessagesPlaceholder('conversation')\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "template.invoke(\n",
    "    {\n",
    "        \"conversation\": [\n",
    "            (\"human\", \"Hi!\"),\n",
    "            (\"ai\", \"How can I assist you today?\"),\n",
    "            (\"human\", \"Write an essay on AI Agents? \"),\n",
    "            \n",
    "        ]\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8053b5e5",
   "metadata": {},
   "source": [
    "### FewShortPromptTemplate\n",
    "- The idea is to “train” the model on a few examples — we call this few-shot learning — and these examples are given to the model within the prompt.\n",
    "- Few-shot learning is perfect when our model needs help understanding what we’re asking it to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5a1bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solve the following math problems.\n",
      "\n",
      "Input: 2 + 2\n",
      "Output: 4\n",
      "\n",
      "Input: 3 * 5\n",
      "Output: 15\n",
      "\n",
      "Input: 7 + 6\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import FewShotPromptTemplate\n",
    "\n",
    "\n",
    "examples = [\n",
    "{\"input\": \"2 + 2\", \"output\": \"4\"},\n",
    "{\"input\": \"3 * 5\", \"output\": \"15\"},\n",
    "]\n",
    "\n",
    "\n",
    "example_template = \"Input: {input}\\nOutput: {output}\"\n",
    "example_prompt = PromptTemplate(input_variables=[\"input\", \"output\"], template=example_template)\n",
    "\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "examples=examples,\n",
    "example_prompt=example_prompt,\n",
    "prefix=\"Solve the following math problems.\",\n",
    "suffix=\"Input: {input}\\nOutput:\",\n",
    "input_variables=[\"input\"]\n",
    ")\n",
    "\n",
    "\n",
    "print(few_shot_prompt.format(input=\"7 + 6\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c506fdc",
   "metadata": {},
   "source": [
    "### Best Practices\n",
    "- Keep prompts modular and reusable\n",
    "- Use placeholders for dynamic variables\n",
    "- Include system instructions for clarity\n",
    "- Test variations — small changes in wording matter\n",
    "- Reuse templates across chains and agents\n",
    "\n",
    "\n",
    "\n",
    "### Next in this Series:\n",
    "### “Messages and Chat Models in LangChain — Powering Multi-Turn Conversations with Context”\n",
    "### Explore the complete series here:\n",
    "### https://github.com/Mouli423/LangChain-Generative-AI-Series"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
