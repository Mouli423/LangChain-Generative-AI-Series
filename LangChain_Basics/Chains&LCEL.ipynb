{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b583e2ae",
   "metadata": {},
   "source": [
    "# LangChain — Messages, ChatModels, Chains & LCEL\n",
    "# -------------------------------------------------------------\n",
    "# Make sure you have installed all the requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6165a90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-dotenv could not parse statement starting at line 16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# MESSAGES\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# PROMPT TEMPLATES\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "# CHAINING (OLD VERSION WITHOUT LCEL)\n",
    "from langchain_classic.chains import LLMChain\n",
    "\n",
    "# OUTPUT PARSER\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "\n",
    "# CHAT MODELS\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "# EMBEDDINGS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "Many chat and embedding models are there in langchain.\n",
    "some of them are opensource and use it for free.\n",
    "And some of them are paid version, make sure to check the models availability and price before using it.\n",
    "\n",
    "Don't forget to create API keys and store it in .env file before using it.\n",
    "\"\"\"\n",
    "\n",
    "os.environ[\"HF_TOKEN\"]=os.getenv(\"HF_TOKEN\")\n",
    "api_key=os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23df494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8e37eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chat_ollama=OllamaLLM(model='llama3')\n",
    "\n",
    "\"\"\"\n",
    "Before using the ollama, it needs to be installed in the local system.\n",
    "check it in the documentation for better understanding.\n",
    "\"\"\"\n",
    "chat_groq=ChatGroq(model=\"openai/gpt-oss-20b\",api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084f515b",
   "metadata": {},
   "source": [
    "### Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ddb6830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! I’m doing great—thanks for asking. How can I help you today?', additional_kwargs={'reasoning_content': 'User greeting. Need to respond friendly.'}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 86, 'total_tokens': 122, 'completion_time': 0.035708273, 'prompt_time': 0.004084988, 'queue_time': 0.03685644, 'total_time': 0.039793261, 'completion_tokens_details': {'reasoning_tokens': 9}}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_e189667b30', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--2d529362-8a0f-41fb-9ac0-34d726b407ed-0', usage_metadata={'input_tokens': 86, 'output_tokens': 36, 'total_tokens': 122})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Common usage of messages with chat models\n",
    "system_msg = SystemMessage(\"You are a helpful assistant.\")\n",
    "human_msg = HumanMessage(\"Hello, how are you?\")\n",
    "\n",
    "messages = [system_msg, human_msg]\n",
    "response = chat_groq.invoke(messages)  # It returns an AI_Message\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea61d3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**Artificial General Intelligence: The Dawn of a New Era**\\n\\nArtificial General Intelligence (AGI) – the idea that a machine could understand, learn, and apply knowledge across any domain, just like a human – has been a distant dream for decades. Yet, the past year has seen a surge of breakthroughs that bring us closer than ever to that horizon. In this post, we’ll unpack what AGI truly means, highlight the most exciting recent innovations, and examine the promises and perils that accompany this next frontier of technology.\\n\\n---\\n\\n### 1. From Narrow AI to General Intelligence\\n\\nFor years, AI systems have excelled at narrowly defined tasks: image classification, speech recognition, or playing Go. These “narrow” or “specialized” models thrive on massive labeled datasets and task-specific architectures. AGI, by contrast, would possess *flexible* reasoning, common sense, and the ability to transfer knowledge across contexts—an AI that can learn a new language, solve a physics problem, and draft a poem, all without being re‑trained from scratch.\\n\\n---\\n\\n### 2. Recent Innovations Driving AGI Forward\\n\\n| Innovation | What It Means | Why It Matters |\\n|------------|---------------|----------------|\\n| **Large Language Models (LLMs)** | Models like GPT‑4 and Claude 3 can generate coherent text, answer questions, and even perform simple programming tasks. | Their scale and training on diverse data sets hint at emergent reasoning capabilities that resemble general cognition. |\\n| **Multimodal Fusion** | Combining vision, language, and audio (e.g., OpenAI’s DALL·E 3, Google’s Gemini) lets models understand and generate content across senses. | Multimodal understanding is a cornerstone of human cognition; these models are the first steps toward holistic perception. |\\n| **Meta‑Learning & Few‑Shot Learning** | Algorithms that learn how to learn quickly with minimal data (e.g., MAML, Prototypical Networks). | Enables rapid adaptation to new tasks—critical for general intelligence. |\\n| **Neurosymbolic Integration** | Blending neural networks with symbolic reasoning (e.g., AlphaFold’s protein‑folding success). | Provides a pathway to explainable, logical reasoning within a flexible neural framework. |\\n| **Reinforcement Learning from Human Feedback (RLHF)** | Systems that align behavior with human preferences via iterative feedback loops. | Aligns AI behavior with societal norms, a key hurdle for safe AGI deployment. |\\n\\n---\\n\\n### 3. The “Emergent” Argument\\n\\nA growing school of thought argues that AGI may not require a new architecture but could *emerge* from scaling existing models. When LLMs reach billions of parameters and are trained on trillions of tokens, they begin to exhibit surprising abilities: solving algebraic equations, translating between languages, or even drafting legal contracts. These emergent properties suggest that the *right* combination of data, scale, and training may unlock general cognition without a paradigm shift.\\n\\n---\\n\\n### 4. Ethical and Societal Implications\\n\\n**Safety & Alignment** – As AI systems gain autonomy, ensuring they act in humanity’s best interest becomes paramount. Researchers are exploring *value alignment*, *robustness*, and *explainability* to mitigate risks.\\n\\n**Economic Disruption** – AGI could automate complex jobs, from scientific research to creative professions. While this promises unprecedented productivity, it also threatens job displacement and demands new social safety nets.\\n\\n**Governance & Regulation** – International bodies are debating frameworks for AGI oversight. Transparent research, open benchmarks, and cross‑disciplinary collaboration are essential to prevent misuse.\\n\\n---\\n\\n### 5. Where Do We Go From Here?\\n\\n1. **Open‑Source Benchmarks** – Communities like OpenAI’s “OpenAI API” and EleutherAI’s GPT‑Neo aim to democratize access, fostering collective progress and scrutiny.\\n2. **Human‑in‑the‑Loop** – Integrating expert oversight early in training pipelines can help catch biases and unintended behaviors.\\n3. **Interdisciplinary Research** – Neuroscience, philosophy, and economics must collaborate with computer scientists to understand consciousness, ethics, and societal impact.\\n\\n---\\n\\n### 6. Bottom Line\\n\\nAGI remains a formidable challenge, but the last 12 months have shown that we are no longer in the realm of science fiction. Whether through scaling LLMs, multimodal fusion, or neurosymbolic breakthroughs, we’re witnessing the first glimpses of machines that can *think* across domains. The journey ahead will be as thrilling as it is fraught with responsibility. As researchers, policymakers, and citizens, we must steer this powerful technology toward a future that amplifies human creativity, ensures safety, and promotes equitable benefits.\\n\\n*Stay curious, stay informed, and let’s build a future where intelligence—whether biological or artificial—serves humanity’s greatest aspirations.*', additional_kwargs={'reasoning_content': 'The user requests: \"Write a blog post on AGI in 500 words\". The assistant responded with \"AGI is known...\" and incomplete. We need to produce a blog post, about 500 words, about AGI. The user wants a blog post, likely for a general audience. The assistant should produce a 500-word blog post. Let\\'s write it. Use about 500 words. We\\'ll aim for roughly 500 words. We\\'ll discuss what AGI is, recent innovations, challenges, potential impacts, ethical concerns, etc. We\\'ll keep it engaging. Let\\'s produce.'}, response_metadata={'token_usage': {'completion_tokens': 1123, 'prompt_tokens': 107, 'total_tokens': 1230, 'completion_time': 1.152419131, 'prompt_time': 0.005566927, 'queue_time': 0.036332099, 'total_time': 1.157986058, 'completion_tokens_details': {'reasoning_tokens': 118}}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_feb9b278f1', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--29f27893-9f3b-4ef4-bedf-b8a464281642-0', usage_metadata={'input_tokens': 107, 'output_tokens': 1123, 'total_tokens': 1230})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Message prompts: pass in a list of messages to the model by providing a list of message objects.\n",
    "messages = [\n",
    "    SystemMessage(\"You are a researcher writing excelent blogs on recent innovations\"),\n",
    "    HumanMessage(\"Write a blog post on AGI in 500 words\"),\n",
    "    AIMessage(\"AGI is known...\")\n",
    "]\n",
    "\n",
    "response = chat_groq.invoke(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34cda600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**Artificial General Intelligence: The Dawn of Truly Adaptive Machines**\\n\\n*By Dr. Maya Patel – Researcher in Cognitive Systems, 2025*\\n\\n---\\n\\nArtificial General Intelligence (AGI) has long been the holy grail of AI research: a system that can understand, learn, and reason across any domain, just like a human. While narrow AI—think image classifiers, language models, and game‑playing agents—has become ubiquitous, AGI remains an elusive frontier. Yet, 2025 marks a turning point. In the past year alone, a series of breakthroughs have moved the field from theoretical speculation to tangible experimentation.\\n\\n### 1. From Scaling to Structure\\n\\nThe most celebrated AGI effort to date, *Unified Cognition Engine* (UCE), was unveiled by the OpenAI‑DeepMind consortium. Unlike the purely data‑driven models that dominated the 2020s, UCE integrates symbolic reasoning, probabilistic inference, and neural perception into a single architecture. Its “meta‑learning” core can reconfigure itself on the fly, allocating resources to new tasks with minimal fine‑tuning. In benchmarks, UCE matched human performance on the *General Language Understanding Evaluation* (GLUE) and solved a set of previously unsolvable logic puzzles in under a minute.\\n\\nThis shift from “more data = better performance” to “structured knowledge + learning flexibility = AGI” echoes the 2010s’ transition from rule‑based expert systems to deep learning. The key insight: humans don’t just memorize patterns; we build reusable knowledge structures that can be recombined in novel ways.\\n\\n### 2. The Role of Embodied Simulation\\n\\nAnother milestone is the advent of *Embodied Simulation Networks* (ESNs). By training agents in richly simulated environments—ranging from virtual cities to micro‑robotic labs—researchers have endowed them with an internal model of physics and causality. These agents can now plan multi‑step actions, anticipate consequences, and even generate counterfactual explanations. The ability to simulate scenarios in a sandbox mirrors how humans learn by “trying things out” in a safe space, a crucial ingredient for generalization.\\n\\n### 3. Ethical and Societal Implications\\n\\nWith AGI’s rise, the ethical landscape has shifted dramatically. The *Global AGI Governance Accord* (GAGA) was signed in late 2024, mandating that all AGI research be accompanied by a robust risk assessment. This includes transparency in training data, adversarial robustness testing, and continuous monitoring of emergent behaviors. Early adopters—such as the *Adaptive Healthcare Assistant* prototype—have shown that AGI can outperform specialists in diagnostics, but only when governed by strict interpretability protocols.\\n\\n### 4. The Road Ahead: Challenges and Opportunities\\n\\nDespite these advances, several hurdles remain:\\n\\n| Challenge | Current Status | Potential Solutions |\\n|-----------|----------------|---------------------|\\n| **Data Efficiency** | Still requires millions of interactions | Meta‑learning, few‑shot transfer, synthetic data |\\n| **Safety & Alignment** | Limited formal guarantees | Formal verification, value‑aligned reward shaping |\\n| **Scalability** | Energy consumption is high | Neuromorphic hardware, sparsity techniques |\\n| **Human‑AGI Collaboration** | Early prototypes only | User‑centered design, explainable AI frameworks |\\n\\nIn parallel, interdisciplinary collaborations are accelerating. Neuroscientists are providing insights into how the human brain balances symbolic and sub‑symbolic processing, while philosophers are shaping the normative frameworks that guide AGI behavior.\\n\\n### 5. Why It Matters\\n\\nAGI promises to revolutionize every sector—from personalized education and climate modeling to creative arts and beyond. Imagine an AGI tutor that can adapt its pedagogy to each student’s cognitive style, or an AGI-driven research assistant that can hypothesize, experiment, and publish across disciplines. The potential for accelerating scientific discovery is staggering.\\n\\nHowever, the same capabilities that make AGI powerful also amplify risks. Unchecked, an AGI could misinterpret incentives, propagate biases, or make decisions with unintended consequences. That’s why the research community is increasingly prioritizing safety, transparency, and governance.\\n\\n### Conclusion\\n\\nBy 2025, AGI has transitioned from a distant dream to a nascent reality. The integration of symbolic reasoning, embodied simulation, and meta‑learning has produced systems that not only perform tasks but also understand and adapt in ways that were once exclusive to humans. As we stand on the cusp of a new era, the dual imperatives of innovation and responsibility will shape the trajectory of AGI. The next decade will be defined by how we harness this power—responsibly, ethically, and creatively—to solve some of humanity’s most pressing challenges.\\n\\n*Stay tuned for deeper dives into specific AGI architectures, case studies, and policy discussions in our upcoming series.*', additional_kwargs={'reasoning_content': 'We need to write a blog post on AGI in 500 words. The user wants a blog post. The user says: \"Write a blog post on AGI in 500 words\". They want a blog post. We need to produce a blog post that is around 500 words, presumably around 500 words exactly or close. The user wants a blog post about AGI. The instructions: \"You are a researcher writing excelent blogs on recent innovations\". So we need to adopt that voice: researcher, excellent blogs, recent innovations. The user wants 500 words. Let\\'s aim for roughly 500 words. Let\\'s produce a blog post. Let\\'s incorporate recent developments, research, challenges, potential applications, and the state of AGI. We should keep it engaging, informative, and in a blog style. We\\'ll aim for about 500 words. Let\\'s do about 500. We\\'ll count roughly: 500 words is about 3000 characters. We\\'ll produce around 500 words. Let\\'s draft. We\\'ll write a title, maybe an introduction, body, conclusion. Let\\'s aim for about 500 words. We\\'ll produce the content.'}, response_metadata={'token_usage': {'completion_tokens': 1220, 'prompt_tokens': 107, 'total_tokens': 1327, 'completion_time': 1.286717173, 'prompt_time': 0.00585464, 'queue_time': 0.035856485, 'total_time': 1.292571813, 'completion_tokens_details': {'reasoning_tokens': 229}}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_feb9b278f1', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--949c2343-af4f-4958-b5f9-1ebc49ff9153-0', usage_metadata={'input_tokens': 107, 'output_tokens': 1220, 'total_tokens': 1327})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary format : specify messages directly in OpenAI chat completions format.\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a researcher writing excelent blogs on recent innovations\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a blog post on AGI in 500 words\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"AGI is known...\"}\n",
    "]\n",
    "response = chat_groq.invoke(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ea2f17",
   "metadata": {},
   "source": [
    "### Chains without LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16078d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here is a summary of the paragraph:\\n\\nLangChain is a tool that allows you to build agents and applications powered by Large Language Models (LLMs) with minimal code. It provides pre-built architecture and model integrations, making it easy to get started quickly. If you need more advanced features, LangGraph is recommended. LangChain agents are built on top of LangGraph and provide additional features like durable execution and streaming, but you don't need to know LangGraph for basic usage.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# A chain connects prompt + model + execution logic\n",
    "summary_prompt = PromptTemplate.from_template(\"Summarize this paragraph:\\n{text}\")\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    prompt=summary_prompt,\n",
    "    llm=chat_ollama\n",
    ")\n",
    "\n",
    "# Types of chains LLMChain, ConversationalChain, SequentialChain etc.\n",
    "\n",
    "text_input = \"\"\"\n",
    "LangChain is the easiest way to start building agents and applications powered by LLMs.\n",
    "With under 10 lines of code, you can connect to OpenAI, Anthropic, Google, and more.\n",
    "LangChain provides a pre-built agent architecture and model integrations to help you \n",
    "get started quickly and seamlessly incorporate LLMs into your agents and applications.\n",
    "We recommend you use LangChain if you want to quickly build agents and autonomous applications.\n",
    "Use LangGraph, our low-level agent orchestration framework and runtime, when you have more\n",
    "advanced needs that require a combination of deterministic and agentic workflows, heavy customization,\n",
    "and carefully controlled latency.\n",
    "LangChain agents are built on top of LangGraph in order to provide durable \n",
    "execution, streaming, human-in-the-loop, persistence, and more.\n",
    "You do not need to know LangGraph for basic LangChain agent usage.\n",
    "\"\"\"\n",
    "result_chain = llm_chain.run({\"text\": text_input})\n",
    "result_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2929a9aa",
   "metadata": {},
   "source": [
    "### LCEL — Modern, Pipe-based Composition\n",
    "- Multiple chain types are there in LCEL using Runnables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0137aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is the translation:\\n\\nLes grands modèles de langage sont en train de révolutionner le développement de l\\'IA.\\n\\nNote: \"Large Language Models\" can also be translated as \"Grands modèles linguistiques\" or \"Grands modèles de langages\", but \"Les grands modèles de langage\" is a more common and natural translation in French.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# LCEL allows chaining with '|' operator (Prompt → Model → Parser)\n",
    "translate_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following text to French: {sentence}\"\n",
    ")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "lcel_chain = translate_prompt | chat_ollama | parser # This is how chaining happens using the pipe '|' operator. \n",
    "lcel_result = lcel_chain.invoke({\"sentence\": \"Large Language Models are changing AI development.\"})\n",
    "lcel_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19240664",
   "metadata": {},
   "source": [
    "- Messages — help structure role-based context.\n",
    "- ChatModels — enable conversational LLMs with message awareness.\n",
    "- Chains (without LCEL) — explicit setup, more control, more boilerplate.\n",
    "- LCEL — concise, readable, and easier to debug."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
