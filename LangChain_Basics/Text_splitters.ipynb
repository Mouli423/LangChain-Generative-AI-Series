{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c275df15",
   "metadata": {},
   "source": [
    "# LangChain Text Splitters – A Hands-On Guide\n",
    "\n",
    "This repository demonstrates how **LangChain Text Splitters** are used to divide large documents into smaller, meaningful chunks for better embeddings and retrieval in **Generative AI pipelines**.\n",
    "\n",
    "## Why Text Splitting?\n",
    "\n",
    "LLMs (like GPT-5, Groq, Gemini or Claude) have input size limits (token windows). Large documents can exceed those limits, causing:\n",
    "- Lost context or truncated responses  \n",
    "- Poor embedding quality  \n",
    "- Slow and inefficient retrieval  \n",
    "\n",
    "Text splitters solve this by **dividing text into overlapping, context-preserving chunks** before embedding or retrieval.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2844ab54",
   "metadata": {},
   "source": [
    "# 1. TokenTextSplitter \n",
    "### It splits the data by token count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b3584a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './speech.txt'}, page_content='The world must be made safe for democracy. Its peace must be planted upon the tested foundations of political liberty. We have no selfish ends to serve. We desire no conquest, no dominion. We seek no indemnities for ourselves, no material compensation for the sacrifices we shall freely make. We are but one of the champions of the rights of mankind. We shall be satisfied when those rights have been made as secure as the faith and the freedom of nations can make them.\\n\\nJust because we fight'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content=' those rights have been made as secure as the faith and the freedom of nations can make them.\\n\\nJust because we fight without rancor and without selfish object, seeking nothing for ourselves but what we shall wish to share with all free peoples, we shall, I feel confident, conduct our operations as belligerents without passion and ourselves observe with proud punctilio the principles of right and of fair play we profess to be fighting for.\\n\\n…\\n\\nIt will be all the easier for'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content=' of right and of fair play we profess to be fighting for.\\n\\n…\\n\\nIt will be all the easier for us to conduct ourselves as belligerents in a high spirit of right and fairness because we act without animus, not in enmity toward a people or with the desire to bring any injury or disadvantage upon them, but only in armed opposition to an irresponsible government which has thrown aside all considerations of humanity and of right and is running amuck. We are, let me'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content=' an irresponsible government which has thrown aside all considerations of humanity and of right and is running amuck. We are, let me say again, the sincere friends of the German people, and shall desire nothing so much as the early reestablishment of intimate relations of mutual advantage between us—however hard it may be for them, for the time being, to believe that this is spoken from our hearts.\\n\\nWe have borne with their present government through all these bitter months because of that friendship—ex'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content=' spoken from our hearts.\\n\\nWe have borne with their present government through all these bitter months because of that friendship—exercising a patience and forbearance which would otherwise have been impossible. We shall, happily, still have an opportunity to prove that friendship in our daily attitude and actions toward the millions of men and women of German birth and native sympathy who live among us and share our life, and we shall be proud to prove it toward all who are in fact loyal to their neighbors and to'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content=' and share our life, and we shall be proud to prove it toward all who are in fact loyal to their neighbors and to the government in the hour of test. They are, most of them, as true and loyal Americans as if they had never known any other fealty or allegiance. They will be prompt to stand with us in rebuking and restraining the few who may be of a different mind and purpose. If there should be disloyalty, it will be dealt with with a firm'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content=' may be of a different mind and purpose. If there should be disloyalty, it will be dealt with with a firm hand of stern repression; but, if it lifts its head at all, it will lift it only here and there and without countenance except from a lawless and malignant few.\\n\\nIt is a distressing and oppressive duty, gentlemen of the Congress, which I have performed in thus addressing you. There are, it may be, many months of fiery trial and'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content=' the Congress, which I have performed in thus addressing you. There are, it may be, many months of fiery trial and sacrifice ahead of us. It is a fearful thing to lead this great peaceful people into war, into the most terrible and disastrous of all wars, civilization itself seeming to be in the balance. But the right is more precious than peace, and we shall fight for the things which we have always carried nearest our hearts—for democracy, for the right of those who submit to authority'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content=' fight for the things which we have always carried nearest our hearts—for democracy, for the right of those who submit to authority to have a voice in their own governments, for the rights and liberties of small nations, for a universal dominion of right by such a concert of free peoples as shall bring peace and safety to all nations and make the world itself at last free.\\n\\nTo such a task we can dedicate our lives and our fortunes, everything that we are and everything that we have, with'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='\\nTo such a task we can dedicate our lives and our fortunes, everything that we are and everything that we have, with the pride of those who know that the day has come when America is privileged to spend her blood and her might for the principles that gave her birth and happiness and the peace which she has treasured. God helping her, she can do no other.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "loader = TextLoader(\"./speech.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = TokenTextSplitter(chunk_size=100, chunk_overlap=25)\n",
    "\n",
    "texts = text_splitter.split_documents(docs)\n",
    "texts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5543a057",
   "metadata": {},
   "source": [
    "# 2. CharacterTextSplitter - The text is split based on the number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf8ac5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 470, which is longer than the specified 75\n",
      "Created a chunk of size 347, which is longer than the specified 75\n",
      "Created a chunk of size 668, which is longer than the specified 75\n",
      "Created a chunk of size 982, which is longer than the specified 75\n",
      "Created a chunk of size 789, which is longer than the specified 75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './speech.txt'}, page_content='The world must be made safe for democracy. Its peace must be planted upon the tested foundations of political liberty. We have no selfish ends to serve. We desire no conquest, no dominion. We seek no indemnities for ourselves, no material compensation for the sacrifices we shall freely make. We are but one of the champions of the rights of mankind. We shall be satisfied when those rights have been made as secure as the faith and the freedom of nations can make them.'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='Just because we fight without rancor and without selfish object, seeking nothing for ourselves but what we shall wish to share with all free peoples, we shall, I feel confident, conduct our operations as belligerents without passion and ourselves observe with proud punctilio the principles of right and of fair play we profess to be fighting for.'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='…'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='It will be all the easier for us to conduct ourselves as belligerents in a high spirit of right and fairness because we act without animus, not in enmity toward a people or with the desire to bring any injury or disadvantage upon them, but only in armed opposition to an irresponsible government which has thrown aside all considerations of humanity and of right and is running amuck. We are, let me say again, the sincere friends of the German people, and shall desire nothing so much as the early reestablishment of intimate relations of mutual advantage between us—however hard it may be for them, for the time being, to believe that this is spoken from our hearts.'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='We have borne with their present government through all these bitter months because of that friendship—exercising a patience and forbearance which would otherwise have been impossible. We shall, happily, still have an opportunity to prove that friendship in our daily attitude and actions toward the millions of men and women of German birth and native sympathy who live among us and share our life, and we shall be proud to prove it toward all who are in fact loyal to their neighbors and to the government in the hour of test. They are, most of them, as true and loyal Americans as if they had never known any other fealty or allegiance. They will be prompt to stand with us in rebuking and restraining the few who may be of a different mind and purpose. If there should be disloyalty, it will be dealt with with a firm hand of stern repression; but, if it lifts its head at all, it will lift it only here and there and without countenance except from a lawless and malignant few.'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='It is a distressing and oppressive duty, gentlemen of the Congress, which I have performed in thus addressing you. There are, it may be, many months of fiery trial and sacrifice ahead of us. It is a fearful thing to lead this great peaceful people into war, into the most terrible and disastrous of all wars, civilization itself seeming to be in the balance. But the right is more precious than peace, and we shall fight for the things which we have always carried nearest our hearts—for democracy, for the right of those who submit to authority to have a voice in their own governments, for the rights and liberties of small nations, for a universal dominion of right by such a concert of free peoples as shall bring peace and safety to all nations and make the world itself at last free.'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='To such a task we can dedicate our lives and our fortunes, everything that we are and everything that we have, with the pride of those who know that the day has come when America is privileged to spend her blood and her might for the principles that gave her birth and happiness and the peace which she has treasured. God helping her, she can do no other.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter=CharacterTextSplitter(\n",
    "    separator='\\n',\n",
    "    chunk_size=75,\n",
    "    chunk_overlap=15\n",
    ")\n",
    "\n",
    "texts=text_splitter.split_documents(docs)\n",
    "\n",
    "\"\"\"Text will be split only at new lines since we are using the new line (“\\n”) as the separator.\n",
    " If any chunk has a size more than 75 but no new lines in it, it will be returned as such.\"\"\"\n",
    "\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58194dac",
   "metadata": {},
   "source": [
    "# 3. RecursiveCharacterTextSplitter\n",
    "\n",
    "### This method uses multiple separators recursively to split the data until the chunk reaches the less than the chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf7c0bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './speech.txt'}, page_content='The world must be made safe for democracy.'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='Its peace must be planted upon the tested foundations of political liberty.'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='We have no selfish ends to serve.(?<=[.,])\\\\s+We desire no conquest,(?<=[.,])\\\\s+no dominion.'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='no dominion.(?<=[.,])\\\\s+We seek no indemnities for ourselves,'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='no material compensation for the sacrifices we shall freely make.'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='We are but one of the champions of the rights of mankind.'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='We shall be satisfied when those rights have been made as secure as the faith and the freedom of nations can make them.'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='Just because we fight without rancor and without selfish object,'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='seeking nothing for ourselves but what we shall wish to share with all free peoples,'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='we shall,(?<=[.,])\\\\s+I feel confident,'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='conduct our operations as belligerents without passion and ourselves observe with proud punctilio the principles of right and of fair play we profess to be fighting for.'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='…'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='It will be all the easier for us to conduct ourselves as belligerents in a high spirit of right and fairness because we act without animus,'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='not in enmity toward a people or with the desire to bring any injury or disadvantage upon them,'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='but only in armed opposition to an irresponsible government which has thrown aside all considerations of humanity and of right and is running amuck.'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='We are,(?<=[.,])\\\\s+let me say again,(?<=[.,])\\\\s+the sincere friends of the German people,'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='and shall desire nothing so much as the early reestablishment of intimate relations of mutual advantage between us—however hard it may be for them,'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='for the time being,(?<=[.,])\\\\s+to believe that this is spoken from our hearts.'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='We have borne with their present government through all these bitter months because of that friendship—exercising a patience and forbearance which would otherwise have been impossible.'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='We shall,(?<=[.,])\\\\s+happily,'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='still have an opportunity to prove that friendship in our daily attitude and actions toward the millions of men and women of German birth and native sympathy who live among us and share our life,'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='and we shall be proud to prove it toward all who are in fact loyal to their neighbors and to the government in the hour of test.'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='They are,(?<=[.,])\\\\s+most of them,'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='as true and loyal Americans as if they had never known any other fealty or allegiance.'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='They will be prompt to stand with us in rebuking and restraining the few who may be of a different mind and purpose.'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='If there should be disloyalty,'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='it will be dealt with with a firm hand of stern repression; but,'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='if it lifts its head at all,'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='it will lift it only here and there and without countenance except from a lawless and malignant few.'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='It is a distressing and oppressive duty,(?<=[.,])\\\\s+gentlemen of the Congress,'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='which I have performed in thus addressing you.(?<=[.,])\\\\s+There are,(?<=[.,])\\\\s+it may be,'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='it may be,(?<=[.,])\\\\s+many months of fiery trial and sacrifice ahead of us.'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='It is a fearful thing to lead this great peaceful people into war,'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='into the most terrible and disastrous of all wars,'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='civilization itself seeming to be in the balance.'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='But the right is more precious than peace,'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='and we shall fight for the things which we have always carried nearest our hearts—for democracy,'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='for the right of those who submit to authority to have a voice in their own governments,'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='for the rights and liberties of small nations,'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='for a universal dominion of right by such a concert of free peoples as shall bring peace and safety to all nations and make the world itself at last free.'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='To such a task we can dedicate our lives and our fortunes,'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='everything that we are and everything that we have,'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='with the pride of those who know that the day has come when America is privileged to spend her blood and her might for the principles that gave her birth and happiness and the peace which she has treasured.'),\n",
       " Document(metadata={'source': './speech.txt'}, page_content='God helping her,(?<=[.,])\\\\s+she can do no other.')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    separators=['\\n\\n',r\"(?<=[.,])\\s+\"],\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    is_separator_regex=True,\n",
    "    keep_separator=False\n",
    ")\n",
    "\n",
    "texts=text_splitter.split_documents(docs)\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4be306",
   "metadata": {},
   "source": [
    "# 4. MarkdownHeaderTextSplitter \n",
    "### It is used when the text follows a structured Markdown format —  \n",
    "### like articles, documentation, or hierarchical notes (with `#`, `##`, `###` headers, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dac7893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Header 1': 'LangChain TextSplitters'}, page_content='Text Splitters are most important elements the langchain pipeline which divides the data in meaningful chunks.'),\n",
       " Document(metadata={'Header 1': 'LangChain TextSplitters', 'Header 2': 'Types of TextSplitters'}, page_content='1.  Length-Based\\n2. Text Structured Based\\n3. Document Structured Based\\n4. Semantic Meaning Based'),\n",
       " Document(metadata={'Header 1': 'LangChain TextSplitters', 'Header 2': 'Types of TextSplitters', 'Header 3': 'Reasons to Splt documents'}, page_content='1. Handling non-uniform document lengths\\n2. Overcoming model limitations\\n3. Improving representaion quality\\n4. Optimizing Computational Resources')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "\n",
    "markdown_text = \"\"\"\n",
    "# LangChain TextSplitters\n",
    "Text Splitters are most important elements the langchain pipeline which divides the data in meaningful chunks.\n",
    "## Types of TextSplitters\n",
    "1.  Length-Based\n",
    "2. Text Structured Based\n",
    "3. Document Structured Based\n",
    "4. Semantic Meaning Based\n",
    "### Reasons to Splt documents\n",
    "1. Handling non-uniform document lengths\n",
    "2. Overcoming model limitations\n",
    "3. Improving representaion quality\n",
    "4. Optimizing Computational Resources\n",
    "\"\"\"\n",
    "\n",
    "splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=[(\"#\", \"Header 1\"), (\"##\", \"Header 2\"),('###','Header 3')]\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(markdown_text)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8697c65f",
   "metadata": {},
   "source": [
    "# 5. HTMLHeaderTextSplitter\n",
    "### It is a \"structure-aware\" text splitter that splits text at the HTML element level and adds metadata for each header \"relevant\" to any given chunk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a2a103",
   "metadata": {},
   "source": [
    "Choosing the Right Splitter\n",
    "- HTMLHeaderTextSplitter:When You need to split an HTML document based on its header hierarchy and maintain metadata about the headers.\n",
    "- Use HTMLSectionSplitter when: You need to split the document into larger, more general sections, possibly based on custom tags or font sizes.\n",
    "- Use HTMLSemanticPreservingSplitter when: You need to split the document into chunks while preserving semantic elements like tables and lists, ensuring that they are not split and that their context is maintained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee57736f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='!function(){function t(t){document.documentElement.setAttribute(\"data-theme\",t)}var e=function(){try{return new URLSearchParams(window.location.search).get(\"docusaurus-theme\")}catch(t){}}()||function(){try{return window.localStorage.getItem(\"theme\")}catch(t){}}();null!==e?t(e):window.matchMedia(\"(prefers-color-scheme: dark)\").matches?t(\"dark\"):(window.matchMedia(\"(prefers-color-scheme: light)\").matches,t(\"light\"))}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith(\"docusaurus-data-\")){var a=t.replace(\"docusaurus-data-\",\"data-\");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute(\"data-announcement-bar-initially-dismissed\",function(){try{return\"true\"===localStorage.getItem(\"docusaurus.announcement.dismiss\")}catch(t){}return!1}())  \\nSkip to main content  \\n⚠️ THESE DOCS ARE OUTDATED.  \\nVisit the new v1.0 docs  \\nIntegrations  \\nAPI Reference  \\nMore  \\nContributing  \\nPeople  \\nError reference  \\nLangSmith  \\nLangGraph  \\nLangChain Hub  \\nLangChain JS/TS  \\nv0.3  \\nv0.3  \\nv0.2  \\nv0.1  \\n💬  \\nSearch  \\nIntroduction  \\nTutorials  \\nBuild a Question Answering application over a Graph Database  \\nindex  \\nBuild a simple LLM application with chat models and prompt templates  \\nBuild a Chatbot  \\nBuild a Retrieval Augmented Generation (RAG) App: Part 2  \\nBuild an Extraction Chain  \\nBuild an Agent  \\nTagging  \\nBuild a Retrieval Augmented Generation (RAG) App: Part 1  \\nBuild a semantic search engine  \\nBuild a Question/Answering system over SQL data  \\nSummarize Text  \\nHow-to guides  \\nindex  \\nHow to use tools in a chain  \\nHow to use a vectorstore as a retriever  \\nHow to add memory to chatbots  \\nHow to use example selectors  \\nHow to add a semantic layer over graph database  \\nHow to invoke runnables in parallel  \\nHow to stream chat model responses  \\nHow to add default invocation args to a Runnable  \\nHow to add retrieval to chatbots  \\nHow to use few shot examples in chat models  \\nHow to do tool/function calling  \\nHow to install LangChain packages  \\nHow to add examples to the prompt for query analysis  \\nHow to use few shot examples  \\nHow to run custom functions  \\nHow to use output parsers to parse an LLM response into structured format  \\nHow to handle cases where no queries are generated  \\nHow to route between sub-chains  \\nHow to return structured data from a model  \\nHow to summarize text through parallelization  \\nHow to summarize text through iterative refinement  \\nHow to summarize text in a single LLM call  \\nHow to use toolkits  \\nHow to add ad-hoc tool calling capability to LLMs and Chat Models  \\nBuild an Agent with AgentExecutor (Legacy)  \\nHow to construct knowledge graphs  \\nHow to partially format prompt templates  \\nHow to handle multiple queries when doing query analysis  \\nHow to use built-in tools and toolkits  \\nHow to pass through arguments from one step to the next  \\nHow to compose prompts together  \\nHow to handle multiple retrievers when doing query analysis  \\nHow to add values to a chain\\'s state  \\nHow to construct filters for query analysis  \\nHow to configure runtime chain internals  \\nHow to deal with high-cardinality categoricals when doing query analysis  \\nCustom Document Loader  \\nHow to use the MultiQueryRetriever  \\nHow to add scores to retriever results  \\nCaching  \\nHow to use callbacks in async environments  \\nHow to attach callbacks to a runnable  \\nHow to propagate callbacks  constructor  \\nHow to dispatch custom callback events  \\nHow to pass callbacks in at runtime  \\nHow to split by character  \\nHow to cache chat model responses  \\nHow to handle rate limits  \\nHow to init any model in one line  \\nHow to track token usage in ChatModels  \\nHow to add tools to chatbots  \\nHow to split code  \\nHow to do retrieval with contextual compression  \\nHow to convert Runnables to Tools  \\nHow to create custom callback handlers  \\nHow to create a custom chat model class  \\nCustom Embeddings  \\nHow to create a custom LLM class  \\nCustom Retriever  \\nHow to create tools  \\nHow to debug your LLM apps  \\nHow to load CSVs  \\nHow to load documents from a directory  \\nHow to load HTML  \\nHow to load JSON  \\nHow to load Markdown  \\nHow to load Microsoft Office files  \\nHow to load PDFs  \\nHow to load web pages  \\nHow to create a dynamic (self-constructing) chain  \\nText embedding models  \\nHow to combine results from multiple retrievers  \\nHow to select examples from a LangSmith dataset  \\nHow to select examples by length  \\nHow to select examples by maximal marginal relevance (MMR)  \\nHow to select examples by n-gram overlap  \\nHow to select examples by similarity  \\nHow to use reference examples when doing extraction  \\nHow to handle long text when doing extraction  \\nHow to use prompting alone (no tool calling) to do extraction  \\nHow to add fallbacks to a runnable  \\nHow to filter messages  \\nHybrid Search  \\nHow to use the LangChain indexing API  \\nHow to inspect runnables  \\nLangChain Expression Language Cheatsheet  \\nHow to cache LLM responses  \\nHow to track token usage for LLMs  \\nRun models locally  \\nHow to get log probabilities  \\nHow to reorder retrieved results to mitigate the \"lost in the middle\" effect  \\nHow to split Markdown by Headers  \\nHow to merge consecutive messages of the same type  \\nHow to add message history  \\nHow to migrate from legacy LangChain agents to LangGraph  \\nHow to retrieve using multiple vectors per document  \\nHow to pass multimodal data to models  \\nHow to use multimodal prompts  \\nHow to create a custom Output Parser  \\nHow to use the output-fixing parser  \\nHow to parse JSON output  \\nHow to retry when a parsing error occurs  \\nHow to parse text from message objects  \\nHow to parse XML output  \\nHow to parse YAML output  \\nHow to use the Parent Document Retriever  \\nHow to use LangChain with different Pydantic versions  \\nHow to add chat history  \\nHow to get a RAG application to add citations  \\nHow to do per-user retrieval  \\nHow to get your RAG application to return sources  \\nHow to stream results from your RAG application  \\nHow to split JSON data  \\nHow to recursively split text by characters  \\nResponse metadata  \\nHow to pass runtime secrets to runnables  \\nHow to do \"self-querying\" retrieval  \\nHow to split text based on semantic similarity  \\nHow to chain runnables  \\nHow to save and load LangChain objects  \\nHow to split text by tokens  \\nHow to split HTML  \\nHow to do question answering over CSVs  \\nHow to deal with large databases when doing SQL question-answering  \\nHow to better prompt when doing SQL question-answering  \\nHow to do query validation as part of SQL question-answering  \\nHow to stream runnables  \\nHow to stream responses from an LLM  \\nHow to use a time-weighted vector store retriever  \\nHow to return artifacts from a tool  \\nHow to use chat models to call tools  \\nHow to disable parallel tool calling  \\nHow to force models to call a tool  \\nHow to access the RunnableConfig from a tool  \\nHow to pass tool outputs to chat models  \\nHow to pass run time values to tools  \\nHow to stream events from a tool  \\nHow to stream tool calls  \\nHow to convert tools to OpenAI Functions  \\nHow to handle tool errors  \\nHow to use few-shot prompting with tool calling  \\nHow to add a human-in-the-loop for tools  \\nHow to bind model-specific tools  \\nHow to trim messages  \\nHow to create and query vector stores  \\nConceptual guide  \\nAgents  \\nArchitecture  \\nAsync programming with LangChain  \\nCallbacks  \\nChat history  \\nChat models  \\nDocument loaders  \\nEmbedding models  \\nEvaluation  \\nExample selectors  \\nFew-shot prompting  \\nindex  \\nKey-value stores  \\nLangChain Expression Language (LCEL)  \\nMessages  \\nMultimodality  \\nOutput parsers  \\nPrompt Templates  \\nRetrieval augmented generation (RAG)  \\nRetrieval  \\nRetrievers  \\nRunnable interface  \\nStreaming  \\nStructured outputs  \\nTesting  \\nString-in, string-out llms  \\nText splitters  \\nTokens  \\nTool calling  \\nTools  \\nTracing  \\nVector stores  \\nWhy LangChain?  \\nEcosystem  \\n🦜🛠️ LangSmith  \\n🦜🕸️ LangGraph  \\nVersions  \\nv0.3  \\nv0.2  \\nPydantic compatibility  \\nMigrating from v0.0 chains  \\nHow to migrate from v0.0 chains  \\nMigrating from ConstitutionalChain  \\nMigrating from ConversationalChain  \\nMigrating from ConversationalRetrievalChain  \\nMigrating from LLMChain  \\nMigrating from LLMMathChain  \\nMigrating from LLMRouterChain  \\nMigrating from MapReduceDocumentsChain  \\nMigrating from MapRerankDocumentsChain  \\nMigrating from MultiPromptChain  \\nMigrating from RefineDocumentsChain  \\nMigrating from RetrievalQA  \\nMigrating from StuffDocumentsChain  \\nUpgrading to LangGraph memory  \\nHow to migrate to LangGraph memory  \\nHow to use BaseChatMessageHistory with LangGraph  \\nMigrating off ConversationBufferMemory or ConversationStringBufferMemory  \\nMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemory  \\nMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemory  \\nA Long-Term Memory Agent  \\nRelease policy  \\nSecurity Policy  \\nHow-to guides  \\nHow to split HTML  \\nOn this page'),\n",
       " Document(metadata={'Header 1': 'How to split HTML'}, page_content='How to split HTML'),\n",
       " Document(metadata={}, page_content='Splitting HTML documents into manageable chunks is essential for various text processing tasks such as natural language processing, search indexing, and more. In this guide, we will explore three different text splitters provided by LangChain that you can use to split HTML content effectively:  \\nHTMLHeaderTextSplitter  \\nHTMLSectionSplitter  \\nHTMLSemanticPreservingSplitter  \\nEach of these splitters has unique features and use cases. This guide will help you understand the differences between them, why you might choose one over the others, and how to use them effectively.  \\n%pip install -qU langchain-text-splitters'),\n",
       " Document(metadata={'Header 2': 'Overview of the Splitters'}, page_content='Overview of the Splitters'),\n",
       " Document(metadata={'Header 2': 'Overview of the Splitters'}, page_content='\\u200b  \\nHTMLHeaderTextSplitter  \\n\\u200b  \\ninfo  \\nUseful when you want to preserve the hierarchical structure of a document based on its headings.  \\n: Splits HTML text based on header tags (e.g., , , , etc.), and adds metadata for each header relevant to any given chunk.  \\nDescription  \\n<h1>  \\n<h2>  \\n<h3>  \\n:  \\nCapabilities  \\nSplits text at the HTML element level.  \\nPreserves context-rich information encoded in document structures.  \\nCan return chunks element by element or combine elements with the same metadata.  \\nHTMLSectionSplitter  \\n\\u200b  \\ninfo  \\nUseful when you want to split HTML documents into larger sections, such as , , or custom-defined sections.  \\n<section>  \\n<div>  \\n: Similar to HTMLHeaderTextSplitter but focuses on splitting HTML into sections based on specified tags.  \\nDescription  \\n:  \\nCapabilities  \\nUses XSLT transformations to detect and split sections.  \\nInternally uses for large sections.  \\nRecursiveCharacterTextSplitter  \\nConsiders font sizes to determine sections.  \\nHTMLSemanticPreservingSplitter  \\n\\u200b  \\ninfo  \\nIdeal when you need to ensure that structured elements are not split across chunks, preserving contextual relevancy.  \\n: Splits HTML content into manageable chunks while preserving the semantic structure of important elements like tables, lists, and other HTML components.  \\nDescription  \\n:  \\nCapabilities  \\nPreserves tables, lists, and other specified HTML elements.  \\nAllows custom handlers for specific HTML tags.  \\nEnsures that the semantic meaning of the document is maintained.  \\nBuilt in normalization & stopword removal')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_text_splitters import HTMLHeaderTextSplitter,HTMLSectionSplitter,HTMLSemanticPreservingSplitter\n",
    "\n",
    "\"\"\" Splits HTML text based on header tags (e.g.,<h1>, <h2>, <h3>, etc.),\n",
    " and adds metadata for each header relevant to any given chunk\"\"\"\n",
    "\n",
    "url='https://python.langchain.com/docs/how_to/split_html/'\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "    (\"h4\", \"Header 4\"),\n",
    "]\n",
    "\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on)\n",
    "\n",
    "# for local file use html_splitter.split_text_from_file(<path_to_file>)\n",
    "html_header_splits = html_splitter.split_text_from_url(url)\n",
    "html_header_splits[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d59cc5",
   "metadata": {},
   "source": [
    "# 6. RecursiveJsonSplitter\n",
    "### It is used to split nested JSON data into smaller, manageable chunks while preserving hierarchical structure and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9034a0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "{'university': 'Sheffield Hallam University', 'location': 'Sheffield, United Kingdom'}\n",
      "\n",
      "Chunk 2:\n",
      "{'departments': {'0': {'name': 'Computing and AI'}}}\n",
      "\n",
      "Chunk 3:\n",
      "{'departments': {'0': {'courses': {'0': {'course_name': 'MSc Big Data Analytics'}}}}}\n",
      "\n",
      "Chunk 4:\n",
      "{'departments': {'0': {'courses': {'0': {'modules': {'0': {'name': 'Machine Learning', 'credits': 20}, '1': {'name': 'Deep Learning', 'credits': 20}}}}}}}\n",
      "\n",
      "Chunk 5:\n",
      "{'departments': {'0': {'courses': {'0': {'modules': {'2': {'name': 'Big Data Engineering', 'credits': 20}}}}}}}\n",
      "\n",
      "Chunk 6:\n",
      "{'departments': {'0': {'courses': {'1': {'course_name': 'MSc Cyber Security', 'modules': {'0': {'name': 'Network Security', 'credits': 20}, '1': {'name': 'Cryptography', 'credits': 20}}}}}}}\n",
      "\n",
      "Chunk 7:\n",
      "{'departments': {'1': {'name': 'Business and Management'}}}\n",
      "\n",
      "Chunk 8:\n",
      "{'departments': {'1': {'courses': {'0': {'course_name': 'MBA International Business', 'modules': {'0': {'name': 'Global Strategy', 'credits': 20}, '1': {'name': 'Leadership', 'credits': 20}}}}}}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveJsonSplitter\n",
    "\n",
    "# Sample nested JSON data\n",
    "university_data = {\n",
    "    \"university\": \"Sheffield Hallam University\",\n",
    "    \"location\": \"Sheffield, United Kingdom\",\n",
    "    \"departments\": [\n",
    "        {\n",
    "            \"name\": \"Computing and AI\",\n",
    "            \"courses\": [\n",
    "                {\n",
    "                    \"course_name\": \"MSc Big Data Analytics\",\n",
    "                    \"modules\": [\n",
    "                        {\"name\": \"Machine Learning\", \"credits\": 20},\n",
    "                        {\"name\": \"Deep Learning\", \"credits\": 20},\n",
    "                        {\"name\": \"Big Data Engineering\", \"credits\": 20}\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"course_name\": \"MSc Cyber Security\",\n",
    "                    \"modules\": [\n",
    "                        {\"name\": \"Network Security\", \"credits\": 20},\n",
    "                        {\"name\": \"Cryptography\", \"credits\": 20}\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Business and Management\",\n",
    "            \"courses\": [\n",
    "                {\n",
    "                    \"course_name\": \"MBA International Business\",\n",
    "                    \"modules\": [\n",
    "                        {\"name\": \"Global Strategy\", \"credits\": 20},\n",
    "                        {\"name\": \"Leadership\", \"credits\": 20}\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create RecursiveJsonSplitter instance\n",
    "splitter = RecursiveJsonSplitter(max_chunk_size=200)\n",
    "\n",
    "# Split JSON into smaller structured chunks\n",
    "chunks = splitter.split_json(university_data,convert_lists=True)\n",
    "\n",
    "# Print results\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {idx+1}:\\n{chunk}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d98514",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
