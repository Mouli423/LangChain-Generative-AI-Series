{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bfdf0cd",
   "metadata": {},
   "source": [
    "# Understanding All LangChain Runnable Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f73e2b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-dotenv could not parse statement starting at line 16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.runnables import (\n",
    "    RunnableLambda,\n",
    "    RunnableMap,\n",
    "    RunnableSequence,\n",
    "    RunnableBranch,\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough,\n",
    "    RunnablePick\n",
    ")\n",
    "import random\n",
    "\n",
    "os.environ[\"HF_TOKEN\"]=os.getenv(\"HF_TOKEN\")\n",
    "api_key=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3db669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model=ChatGroq(model=\"openai/gpt-oss-20b\",api_key=api_key)\n",
    "parser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7854f918",
   "metadata": {},
   "source": [
    "## RunnableLambda — Wraps any Python function as a Runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02e30428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Warrior's! Welcome to LangChain Runnables.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def greet(name: str):\n",
    "    return f\"Hello, {name}! Welcome to LangChain Runnables.\"\n",
    "\n",
    "r_lambda = RunnableLambda(greet)\n",
    "print(r_lambda.invoke(\"Warrior's\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06dac5a",
   "metadata": {},
   "source": [
    "## RunnableMap — Runs multiple Runnables in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b59a2e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'summary': '**Artificial Intelligence (AI) – A Quick Summary**\\n\\n| Area | Key Points |\\n|------|------------|\\n| **What It Is** | AI is the design of computer systems that can perform tasks normally requiring human intelligence: perception, reasoning, learning, language understanding, and decision‑making. |\\n| **Core Branches** | 1. **Machine Learning (ML)** – Algorithms that learn from data. <br>2. **Deep Learning** – Neural networks with many layers that excel at vision, speech, and language. <br>3. **Natural Language Processing (NLP)** – Understanding and generating human language. <br>4. **Computer Vision** – Interpreting visual input. <br>5. **Robotics & Autonomous Systems** – Physical agents that act in the world. |\\n| **Historical Milestones** | • 1956 Dartmouth Conference (birth of AI). <br>• 1960s–70s rule‑based expert systems. <br>• 1980s–90s resurgence of machine learning (e.g., neural nets, support vector machines). <br>• 2000s–present: Big data, GPUs, deep learning breakthroughs (ImageNet, AlphaGo, GPT‑series). |\\n| **Common Applications** | • Voice assistants (Siri, Alexa). <br>• Recommendation engines (Netflix, Amazon). <br>• Autonomous vehicles. <br>• Medical diagnostics and drug discovery. <br>• Finance (fraud detection, algorithmic trading). <br>• Creative AI (art, music, writing). |\\n| **Ethical & Societal Issues** | • Bias & fairness in training data. <br>• Privacy and surveillance concerns. <br>• Job displacement and economic inequality. <br>• Accountability for autonomous decisions. <br>• Existential risk and alignment with human values. |\\n| **Future Directions** | • **General AI**: systems that can transfer learning across domains. <br>• **Explainable AI**: making decisions transparent. <br>• **Human‑AI collaboration**: augmenting rather than replacing human work. <br>• **AI governance**: global norms, safety standards, and policy frameworks. |\\n\\n**Bottom line:** AI is a rapidly evolving field that blends computer science, statistics, neuroscience, and ethics to create systems capable of performing tasks that once required human cognition. Its reach spans everyday convenience to transformative industry change, while also raising profound questions about fairness, safety, and the future of work.', 'haiku': 'Silent circuits hum—  \\nthoughts bloom in code, unseen,  \\nmind forged from pure light.'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt1 = ChatPromptTemplate.from_template(\"Summarize the topic: {topic}\")\n",
    "prompt2 = ChatPromptTemplate.from_template(\"Write a haiku about {topic}\")\n",
    "\n",
    "chain1 = prompt1 | model | parser\n",
    "chain2 = prompt2 | model | parser\n",
    "\n",
    "r_map = RunnableMap({\n",
    "    \"summary\": chain1,\n",
    "    \"haiku\": chain2\n",
    "})\n",
    "\n",
    "result = r_map.invoke({\"topic\": \"artificial intelligence\"})\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3976988f",
   "metadata": {},
   "source": [
    "## RunnableSequence — Sequential chain of Runnables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c943325e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning is the field of AI that designs algorithms enabling computers to automatically improve their performance on tasks by learning from data rather than being explicitly programmed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Define {term} in one line.\")\n",
    "seq = RunnableSequence(first=prompt, middle=[model], last=parser)\n",
    "print(seq.invoke({\"term\": \"machine learning\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05eb340",
   "metadata": {},
   "source": [
    "## RunnableBranch — Executes conditional logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d5f775e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 is even\n",
      "7 is odd\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def condition_fn(input):\n",
    "    return input[\"number\"] % 2 == 0\n",
    "\n",
    "\n",
    "even_chain = RunnableLambda(lambda x: f\"{x['number']} is even\")\n",
    "odd_chain = RunnableLambda(lambda x: f\"{x['number']} is odd\")\n",
    "\n",
    "\n",
    "r_branch = RunnableBranch(\n",
    "    (condition_fn, even_chain),\n",
    "    odd_chain                  \n",
    ")\n",
    "\n",
    "\n",
    "print(r_branch.invoke({\"number\": 4}))  \n",
    "print(r_branch.invoke({\"number\": 7}))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20551280",
   "metadata": {},
   "source": [
    "## RunnableParallel — Executes multiple branches concurrently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b67d62d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uppercase': 'LANGCHAIN', 'reversed': 'niahCgnaL', 'length': 9}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parallel = RunnableParallel({\n",
    "    \"uppercase\": RunnableLambda(lambda x: x[\"text\"].upper()),\n",
    "    \"reversed\": RunnableLambda(lambda x: x[\"text\"][::-1]),\n",
    "    \"length\": RunnableLambda(lambda x: len(x[\"text\"]))\n",
    "})\n",
    "\n",
    "print(parallel.invoke({\"text\": \"LangChain\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ed648c",
   "metadata": {},
   "source": [
    "## RunnablePassthrough — Returns input as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46d4bbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'msg': 'No transformation happens here'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "passthrough = RunnablePassthrough()\n",
    "print(passthrough.invoke({\"msg\": \"No transformation happens here\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d06ab8",
   "metadata": {},
   "source": [
    "## RunnablePick — Picks a specific field from the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c411c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Engineer\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_runnable = RunnableLambda(lambda _: {\"name\": \"Warrior\", \"role\": \"AI Engineer\", \"country\": \"UK\"})\n",
    "\n",
    "pick_role = RunnablePick(keys=\"role\")\n",
    "\n",
    "print(pick_role.invoke(data_runnable.invoke(None))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b48c9e4",
   "metadata": {},
   "source": [
    "- Refer the below link for more information about types of runnables\n",
    "- https://medium.com/@danushidk507/runnables-in-langchain-e6bfb7b9c0ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320cead8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
